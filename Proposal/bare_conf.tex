
%% bare_conf.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[conference]{IEEEtran}
% Some Computer Society conferences also require the compsoc mode option,
% but others use the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.





\usepackage{url}
\usepackage[fleqn]{amsmath}
\usepackage{algorithm,algpseudocode}
\usepackage{mathtools}
\usepackage{gensymb}
\usepackage{csquotes}
\usepackage{placeins}
% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multilines. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Detection of Pedestrians in Images using SVM\\Project Report}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Gopal Menon}
\IEEEauthorblockA{Machine Learning\\
Fall 2016, University of Utah}
}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract


% no keywords




% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\section{Project Scope}

The scope was to construct a classifier using a Support Vector Machine (SVM) that can classify a street image as one containing or not containing a pedestrian. The main reason why it is interesting to me is that it is one of those problems that can be easily explained to a human, while being extremely difficult to program using traditional methods. 

\begin{figure}[!t]
\centering
\includegraphics[width=2.0in]{./figures/WhichBoundary.png}
\caption{Many possible separating boundaries\cite{SVMPage}}
\label{which}
\end{figure}

An SVM is a linear classifier that finds the separating boundary between instances of two classes or labels. Although there may be many separating boundaries as shown in figure \ref{which}, the linear separation is achieved by selecting a boundary that maximizes the separation between the classes. The vectors that lie on the separating band are called support vectors. These are shown as the solid squares and circle in figure \ref{max}. By finding a such a band that maximizes the separation between classes, the classifier has better generalization for examples that have not been seen yet.
\subsection{Initial Assumptions}
When I started with the project, I went forward with the assumption that through use of a suitable kernel function, images can be linearly separated into ones that contain and do not contain a human. My understanding was that even if the images were not linearly separable in the input space, they would be linearly separable in some higher dimension space through the use of Kernels. Another reason for using an SVM with a Kernel was the belief that since the SVM loss function with respect to the weight vector was convex, it would be possible to find the global minima as opposed to the case for a neural network where I would only be able to find a local minima.

Since then, I learnt during office hours after class that my understanding about the perceived superiority of SVMs when compared to a Neural Network was not correct. Neural Networks have surpassed SVMs in image recognition. Very Deep Convolutional Networks \cite{VGG} are currently the state of the art in image recognition. The suggestion I got during office hours was to use the input to the final layer of a Visual Geometry Group (VGG) Very Deep Convolutional Net (VGG NET) classifier as features for an SVM to do linear separation. 

\begin{figure}[!t]
\centering
\includegraphics[width=2.0in]{./figures/MaxMargin.png}
\caption{Separation with maximum margin\cite{SVMPage}}
\label{max}
\end{figure}

\section{Ideas Explored}
\subsection{SVMs using Non-Linear Kernels}
While looking for project ideas, I had gone through the syllabus and saw that SVMs were going to be covered and decided to do a project using an SVM for pedestrian image classification. What interested me most was the idea of using a linear classifier in a higher dimensional space in order to achieve a non-linear separating boundary in the input space. This is illustrated in figure \ref{NonLinearClassification} where the curved line separating the classes is the decision boundary and the examples marked with the squares are the support vectors that lie on the margin.
\begin{figure}[!t]
\centering
\includegraphics[width=2.0in]{./figures/NonLinearClassification.png}
\caption{Non-Linear linear decision boundary in an SVM achieved through use of a Kernel \cite{AMLBook}}
\label{NonLinearClassification}
\end{figure}

I had read up on the use of Kernels and understood how the Kernel trick could be used to achieve a dot product in a higher dimension space without actually converting the inputs to the function to the higher dimension. I also understood how hard-margin and soft-margin SVMs worked. I understood the mathematical part of the dual form of an SVM where the learnt weight is the sum of products of the $m$ training inputs, labels and an $\alpha$ \cite{AMLBook}.

$$
\textbf{w} = \sum_{i=1}^m \alpha_i y_i \textbf{x}_i
$$

Since the prediction is done using $sgn(\textbf{w}^T\textbf{x})$, it could be represented by

\begin{equation*}
\begin{aligned}
sgn(\textbf{w}^T\textbf{x}) &= \sum_{i=1}^m \alpha_i y_i \textbf{x}_i^T\textbf{x}\\
&= \sum_{i=1}^m \alpha_i y_i K(\textbf{x}_i,\textbf{x})
\end{aligned}
\end{equation*}

where $K$ is a kernel function. I could not map this theory into an algorithm for using a Kernel with an SVM. Also I got feedback on the interim project report that a non-linear kernel SVM was too complex to be done as a class project. This along with the realization that a Neural Net would outperform an SVM with a non-linear kernel, made me drop the idea of using a Kernel.

\subsection{Feature Extraction and Input size reduction}

Since I was going to transform the images to be classified into long pixel intensity vectors, I wanted to do some sort of feature extraction that would make the training task faster and also would allow the feature set to fit into main memory during training. I investigated OpenCV and instead decided to simply scale the images so that the feature vectors would be reduced in size. In addition to scaling the images, I also converted them to grayscale so that I would have one integer per pixel as my features. I used standard Java library functions for the scaling and grayscale conversion.

\subsection{Literature used}

\begin{enumerate}

\item Since I needed to start work on the project before SVMs were covered in class, I used the class recordings from last year to get familiarized with the subject. 

\item In addition to the class recordings, I also used SVM class recordings from a Caltech course on machine learning available at \url{http://amlbook.com} and based on the book \textit{Learning from Data: A Short Course} \cite{AMLBook}. 

\item Once I got comfortable with the material, I referred to the SVM book by Christiani et. al. 2000 \cite{Christiani} for an understanding of the dual form of linear learning machines and kernel functions.

\end{enumerate}

\subsection{Resources used}

The INRIA labelled dataset \cite{INRIA} for humans present and absent was used for training and testing. All the images were of the same size and due to this, no padding of training data vectors with zeroes needed to be done as all the pixel array vectors had the same length. Figures \ref{noperson} and \ref{person} are samples of images from the INRIA dataset that were used in the project.

\begin{figure}[!t]
\centering
\includegraphics[width=2.0in]{./figures/noperson.png}
\caption{Sample of image without person}
\label{noperson}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=2.0in]{./figures/person.png}
\caption{Sample of image with person}
\label{person}
\end{figure}

\section{Ideas used from class}

Since I started the project before SVMs were taught in class, I was still able to use class resources by watching recordings of the class from last year. My SVM was not predicting simple cases correctly and I used feedback from discussions during office hours on how to troubleshoot by using simple inputs with predictable results, setting the seed for the random number generator (used for generating simple test data) so that inputs could be recreated for easier debugging and the very useful suggestion of monitoring the objective so that it reduces. I was able to find and fix a few errors and my SVM started to work. I had coded some kernels (linear, polynomial and Gaussian) but ended up not using them.

\section{Concepts Learnt}

I got a good understanding of SVMs and linear classifiers especially the concept of maximizing the margin for better generalization. I understood the importance of cross validation for selecting hyper-parameters, which was especially useful in building a linear classifier where the inputs were not necessarily fully linearly separable.

I downloaded and used a classifier based on a Deep Convolution Network \cite{Deep4J} and was able to get it to classify the images that were used by the SVM classifier. The accuracy of this classifier far exceeded that for the SVM linear classifier, but this was expected. I however did not get a complete understanding of these classifiers although I think I do have a good understanding of Neural Net classifiers. I am still not sure how I would go about troubleshooting a Neural Network that does not work (due to a bug in back propagation implementation for example). 

\section{Design choices}

\begin{enumerate}

\item I converted the color images to grayscale.
\item Images were scaled to 20\%, 25\% and 30\% of the original size so as to make computational load smaller. Also, because the classifier was failing with memory allocation error when run on the original images.
\item All the images were of the same size and I did not need to pad the feature vectors with zeroes in order to make them of the same size.
\item I used $20$ epochs, $5$-fold cross validation, learning rates from $10^1, 10^0, 10^{-1}, 10^{-2},\ldots, 10^{-10}$ and tradeoff values of $2^1, 2^0, 2^{-1}, 2^{-2},\ldots, 2^{-10}$ for cross validation.
\end{enumerate}

\section{Results}

\begin {table}[H]
\centering
\caption {Testing Data Metrics for SVM Classifier} \label{tab:svmtabtest} 
\begin{tabular}{|c|c|c|c|c|c|}
      \hline
      Scaling & Accuracy & Precision & Recall & F$1$ Score\\
      \hline
      
      20\%                &  0.6370             &  0.7143     & 0.7065 &  0.7104                          \\
      25\%                & 0.6027              &  0.7073     & 0.6304 &   0.6667                       \\
      30\%                &   0.6164            &   0.6800      & 0.7391 &  0.7083                        \\
      \hline
    \end{tabular}
\end{table}

Table \ref{tab:svmtabtest} has the metrics for the SVM classifier on the testing data. The accuracy measures are not very high although I was surprised that I was able to get an F$1$ Score of around $70\%$. I was expecting numbers that were lower than chance as I did not expect the image data to be linearly separable. I expected the numbers to improve when the scaling was reduced (scaling percentage was increased), however the accuracy got worse when scaling was changed from 20\% to 25\% and then increased from 25\% to 30\%. I am not sure how to explain this. With scaling of 20\% the total run time on my laptop was slightly more than $1$ hour and with 30\%, it increased to around $4$ hours. Due to the higher run time at 30\%, I did not try going beyond 30\%. Initially I had tried to run the classifier without any scaling and this resulted in a memory allocation error.

\begin {table}[H]
\centering
\caption {Training Data Metrics for SVM Classifier} \label{tab:svmtabtrain} 
\begin{tabular}{|c|c|c|c|c|c|}
      \hline
      Scaling & Accuracy & Precision & Recall & F$1$ Score\\
      \hline
      
      20\%                &  0.7432             &  0.7489     & 0.8913 &  0.8139                          \\
      25\%                & 0.7568              &  0.7868     & 0.8424 &   0.8136                       \\
      30\%                &   0.7603            &   0.7545      & 0.9185 &  0.8284                        \\
      \hline
    \end{tabular}
\end{table}

Table \ref{tab:svmtabtrain} has the metrics for the SVM classifier on the training data and as expected, the accuracy was higher when compared to the test data.

\begin {table}[H]
\centering
\caption {Metrics for Convolution Net Classifier} \label{tab:cnnmetrics} 
\begin{tabular}{|c|c|c|c|c|c|}
      \hline
      Dataset & Accuracy & Precision & Recall & F$1$ Score\\
      \hline
      
       Testing                & 1.0              &  1.0     & 1.0 &   1.0                       \\
       Training               &  0.9444             &  0.95     & 0.9444 &  0.9472                          \\
      \hline
    \end{tabular}
\end{table}

Table \ref{tab:cnnmetrics} has the metrics for the Convolution Net Classifier and the accuracy of this classifier far exceeded the one using an SVM. This classifier was run using source code that was downloaded \cite{Deep4J} and modified so as to use the same dataset as the SVM classifier. 

Although my plan was to use the inputs to the last layer of the Convolution Net Classifier as the inputs to the SVM classifier, I was not able to do so as internals were not accessible.

\section{If I had more time}

If I had more time or if I knew what I know now at the beginning of the project selection, I would have chosen to use a regular Neural Network or one based on a Convolutional Network as these seem to work best with non-linear classification. I would also have liked to use ensemble classifiers as the idea seems very elegant to me. I would also have tried techniques for image clustering through use of face recognition. I have seen this on iPhones, where the application automatically creates groups of images that contain the same person.

\begin{thebibliography}{1}

\bibitem{SVMPage}
\enquote{Introduction to Support Vector Machines.} \textit{Introduction to Support Vector Machines} - OpenCV 2.4.13.1 Documentation. N.p., n.d. Web. 27 Sept. 2016.

\bibitem{AMLBook}
Abu-Mostafa, Yaser S., Malik Magdon-Ismail, and Hsuan-Tien Lin. \textit{Learning from Data: A Short Course}. United States: AMLBook.com, 2012. Print.

\bibitem{Christiani}
Cristianini, Nello, and John Shawe-Taylor. \textit{An Introduction to Support Vector Machines: And Other Kernel-based Learning Methods}. Cambridge: Cambridge UP, 2000. Print.

\bibitem{INRIA}
\enquote{INRIA Person Dataset.} \textit{INRIA Person Dataset}. N.p., n.d. Web. 08 Nov. 2016.
\bibitem{VGG}
\enquote{Visual Geometry Group Home Page.} \textit{Visual Geometry Group Home Page}. N.p., n.d. Web. 08 Nov. 2016.

\bibitem{Deep4J}
Gibson, Chris Nicholson Adam. \enquote{Deep Learning for Java.} \textit{Deeplearning4j: Open-source, Distributed Deep Learning for the JVM.} N.p., n.d. Web. 15 Dec. 2016.
\end{thebibliography}

\end{document}
